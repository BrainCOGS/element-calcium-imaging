{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataJoint Elements for 2-Photon Calcium Imaging\n",
    "\n",
    "#### Open-source data pipeline for processing and analyzing fluorescent imaging datasets.\n",
    "\n",
    "Welcome to the tutorial for the DataJoint Element for calcium imaging. This tutorial\n",
    "aims to provide a comprehensive understanding of the open-source data pipeline created\n",
    "using `element-calcium-imaging`.\n",
    "\n",
    "This package is designed to seamlessly process, ingest, and track calcium imaging data,\n",
    "along with its associated parameters such as those used for image segmentation or motion\n",
    "correction, and scan-level metadata. By the end of this tutorial, you will have a clear\n",
    "grasp on setting up and integrating `element-calcium-imaging` into your specific\n",
    "research projects and lab.\n",
    "\n",
    "![flowchart](../images/flowchart.svg)\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "Please see the [datajoint tutorials GitHub\n",
    "repository](https://github.com/datajoint/datajoint-tutorials/tree/main) before\n",
    "proceeding.\n",
    "\n",
    "A basic understanding of the following DataJoint concepts will be beneficial to your\n",
    "understanding of this tutorial: \n",
    "1. The `Imported` and `Computed` tables types in `datajoint-python`.\n",
    "2. The functionality of the `.populate()` method. \n",
    "\n",
    "#### **Tutorial Overview**\n",
    "\n",
    "+ Setup\n",
    "+ *Activate* the DataJoint pipeline.\n",
    "+ *Insert* subject, session, and scan metadata.\n",
    "+ *Populate* scan-level metadata from image files.\n",
    "+ Run the image processing task.\n",
    "+ Curate the results (optional).\n",
    "+ Visualize the results.\n",
    "\n",
    "### **Setup**\n",
    "\n",
    "This tutorial examines calcium imaging data acquired with [ScanImage](https://www.mbfbioscience.com/products/scanimage/) and processed via\n",
    "[suite2p](https://www.suite2p.org/). The goal is to store, track, and manage sessions of calcium imaging data,\n",
    "including all outputs of image segmentations, fluorescence traces and deconvolved\n",
    "activity traces. \n",
    "\n",
    "The results of this Element can be combined with **other modalities** to create\n",
    "a complete, customizable data pipeline for your specific lab or study. For instance, you\n",
    "can combine `element-calcium-imaging` with `element-array-ephys` and\n",
    "`element-deeplabcut` to characterize the neural activity along with markless\n",
    "pose-estimation during behavior.\n",
    "\n",
    "Let's start this tutorial by importing the packages necessary to run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the tutorial is run in Codespaces, a private, local database server is created and\n",
    "made available for you. This is where we will insert and store our processed results.\n",
    "let's connect to the database server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.conn()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Activate the DataJoint Pipeline**\n",
    "\n",
    "This tutorial activates the `imaging.py` module from `element-calcium-imaging`, along\n",
    "with upstream dependencies from `element-animal` and `element-session`. Please refer to the\n",
    "[`tutorial_pipeline.py`](./tutorial_pipeline.py) for the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.tutorial_pipeline import (\n",
    "    lab,\n",
    "    subject,\n",
    "    session,\n",
    "    scan,\n",
    "    imaging,\n",
    "    imaging_report,\n",
    "    Equipment,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent the tables in the `scan` and `imaging` schemas as well as some of the\n",
    "upstream dependencies to `session` and `subject` schemas as a diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dj.Diagram(subject.Subject)\n",
    "    + dj.Diagram(session.Session)\n",
    "    + dj.Diagram(scan)\n",
    "    + dj.Diagram(imaging)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As evident from the diagram, this data pipeline encompasses tables associated with\n",
    "scan metadata, results of image processing, and optional curation of image processing\n",
    "results. A few tables, such as `subject.Subject` or `session.Session`,\n",
    "while important for a complete pipeline, fall outside the scope of the `element-calcium-imaging`\n",
    "tutorial, and will therefore, not be explored extensively here. The primary focus of\n",
    "this tutorial will be on the `scan` and `imaging` schemas.\n",
    "\n",
    "### **Insert subject, session, and probe metadata**\n",
    "\n",
    "Let's start with the first table in the schema diagram (i.e. `subject.Subject` table).\n",
    "\n",
    "To know what data to insert into the table, we can view its dependencies and attributes using the `.describe()` and `.heading` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.Subject()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subject.Subject.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.Subject.heading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells above show all attributes of the subject table.\n",
    "We will insert data into the\n",
    "`subject.Subject` table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.Subject.insert1(\n",
    "    dict(\n",
    "        subject=\"subject1\",\n",
    "        subject_nickname=\"subject1_nickname\",\n",
    "        sex=\"F\",\n",
    "        subject_birth_date=\"2020-01-01\",\n",
    "        subject_description=\"ScanImage acquisition. Suite2p processing.\",\n",
    "    )\n",
    ")\n",
    "subject.Subject()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the steps above for the `Session` table and see how the output varies\n",
    "between `.describe` and `.heading`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(session.Session.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.Session.heading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `describe`, displays the table's structure and highlights its dependencies, such as its reliance on the `Subject` table. These dependencies represent foreign key references, linking data across tables.\n",
    "\n",
    "On the other hand, `heading` provides an exhaustive list of the table's attributes. This\n",
    "list includes both the attributes declared in this table and any inherited from upstream\n",
    "tables.\n",
    "\n",
    "With this understanding, let's move on to insert a session associated with our subject.\n",
    "\n",
    "We will insert into the `session.Session` table by passing a dictionary to the `insert1` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_key = dict(subject=\"subject1\", session_datetime=\"2021-04-30 12:22:15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.Session.insert1(session_key)\n",
    "session.Session()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every experimental session produces a set of data files. The purpose of the `SessionDirectory` table is to locate these files. It references a directory path relative to a root directory, defined in `dj.config[\"custom\"]`. More information about `dj.config` is provided in the [documentation](https://datajoint.com/docs/elements/user-guide/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.SessionDirectory.insert1(dict(**session_key, session_dir=\"subject1/session1\"))\n",
    "session.SessionDirectory()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Diagram indicates, the tables in the `scan` schemas need to\n",
    "contain data before the tables in the `imaging` schema accept any data. Let's\n",
    "start by inserting into `scan.Scan`, a table containing metadata about a calcium imaging\n",
    "scan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scan.Scan.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Scan` table's attributes include the `Session` table **and** the `Equipment` table.\n",
    "Let's insert into the `Equipment` table and then `Scan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Equipment.insert1(\n",
    "    dict(\n",
    "        device=\"Scanner1\",\n",
    "        modality=\"Calcium imaging\",\n",
    "        description=\"Example microscope\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.Scan.insert1(\n",
    "    dict(\n",
    "        **session_key,\n",
    "        scan_id=0,\n",
    "        device=\"Scanner1\",\n",
    "        acq_software=\"ScanImage\",\n",
    "        scan_notes=\"\",\n",
    "    )\n",
    ")\n",
    "scan.Scan()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Populate calcium imaging scan metadata**\n",
    "\n",
    "In the upcoming cells, the `.populate()` method will automatically extract and store the\n",
    "recording metadata for each experimental session in the `scan.ScanInfo` table and its part table `scan.ScanInfo.Field`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.ScanInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.ScanInfo.Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration depends on your network bandwidth to s3\n",
    "scan.ScanInfo.populate(display_progress=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the information was entered into each of these tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.ScanInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.ScanInfo.Field()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Run the Processing Task**\n",
    "\n",
    "We're almost ready to perform image processing with `suite2p`. An important step before\n",
    "processing is managing the parameters which will be used in that step. To do so, we will\n",
    "define the suite2p parameters in a dictionary and insert them into a DataJoint table\n",
    "`ProcessingParamSet`. This table keeps track of all combinations of your image\n",
    "processing parameters. You can choose which parameter are used during processing in a\n",
    "later step. \n",
    "\n",
    "Let's view the attributes and insert data into `imaging.ProcessingParamSet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.ProcessingParamSet.heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import suite2p\n",
    "\n",
    "params_suite2p = suite2p.default_ops()\n",
    "params_suite2p[\"nonrigid\"] = False\n",
    "\n",
    "imaging.ProcessingParamSet.insert_new_params(\n",
    "    processing_method=\"suite2p\",\n",
    "    paramset_idx=0,\n",
    "    params=params_suite2p,\n",
    "    paramset_desc=\"Calcium imaging analysis with Suite2p using default parameters\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataJoint uses a `ProcessingTask` table to manage which `Scan` and `ProcessingParamSet`\n",
    "should be used during processing. \n",
    "\n",
    "This table is important for defining several important aspects of downstream processing.\n",
    "Let's view the attributes to get a better understanding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.ProcessingTask.heading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ProcessingTask` table contains two important attributes: \n",
    "+ `paramset_idx` - Allows the user to choose the parameter set with which\n",
    "you want to run image processing.\n",
    "+ `task_mode` - Can be set to `load` or `trigger`. When set to `load`,\n",
    "running the processing step initiates a search for existing output files of the image\n",
    "processing algorithm defined in `ProcessingParamSet`. When set to `trigger`, the\n",
    "processing step will run image processing on the raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.ProcessingTask.insert1(\n",
    "    dict(\n",
    "        **session_key,\n",
    "        scan_id=0,\n",
    "        paramset_idx=0,\n",
    "        task_mode=\"load\",  # load or trigger\n",
    "        processing_output_dir=\"subject1/session1/suite2p\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call populate on the `Processing` table, which checks for Suite2p results since `task_mode=load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Processing.populate(session_key, display_progress=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Populate the results**\n",
    "\n",
    "Once the `Processing` table finishes, we can populate the remaining tables in the\n",
    "workflow including `MotionCorrection`, `Segmentation`, and `Fluorescence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.MotionCorrection.populate(display_progress=True)\n",
    "imaging.Segmentation.populate(display_progress=True)\n",
    "imaging.Fluorescence.populate(display_progress=True)\n",
    "imaging.Activity.populate(display_progress=True)\n",
    "imaging_report.ScanLevelReport.populate(display_progress=True)\n",
    "imaging_report.TraceReport.populate(display_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've populated the tables in this DataJoint pipeline, there are one of\n",
    "several next steps. If you have an existing pipeline for\n",
    "aligning waveforms to behavior data or other stimuli, you can easily\n",
    "invoke `element-event` or define your custom DataJoint tables to extend the\n",
    "pipeline.\n",
    "\n",
    "### **Visualize the results**\n",
    "\n",
    "In this tutorial, we will do some exploratory analysis by fetching the data from the database and creating a few plots."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will fetch the `fluorescence` attribute for `mask=10` with the `fetch1` method by passing the attribute as an argument to the method.\n",
    "\n",
    "By default, `fetch1()` returns all attributes of one of the entries in the table.  If a query has multiple entries, `fetch1()` imports the first entry in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = (imaging.Fluorescence.Trace & \"mask = '10'\").fetch1(\"fluorescence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the query above, we fetch the fluorescence trace from the `Trace` part table\n",
    "belonging to the `Fluorescence` parent table. \n",
    "\n",
    "Let's plot this trace after fetching sampling rate of the data to define the x-axis values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = (scan.ScanInfo & session_key & \"scan_id=0\").fetch1(\"fps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.r_[: trace.size] * 1 / sampling_rate, trace)\n",
    "plt.title(\"Fluorescence trace for mask 10\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Activity (a.u.)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataJoint queries are a highly flexible tool to manipulate and visualize your data.\n",
    "After all, visualizing traces or generating rasters is likely just the start of\n",
    "your analysis workflow. This can also make the queries seem more complex at\n",
    "first. However, we'll walk through them slowly to simplify their content in this notebook. \n",
    "\n",
    "The examples below perform several operations using DataJoint queries:\n",
    "- Fetch the primary key attributes of the scan with `scan_id=0`.\n",
    "- Use **multiple restrictions** to fetch the average motion-corrected image for this\n",
    "  scan with `field_idx=0`.\n",
    "- Use a **join** operation and **multiple restrictions** to fetch ROI mask coordinates\n",
    "  and overlay them on the average motion-corrected image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.MotionCorrection.Summary & session_key & \"scan_id=0\" & \"field_idx=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_image,max_proj_image = (imaging.MotionCorrection.Summary & session_key & \"scan_id=0\" & \"field_idx=0\").fetch1(\n",
    "    \"average_image\",\"max_proj_image\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 16))\n",
    "ax[0].imshow(average_image)\n",
    "ax[1].imshow(max_proj_image)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fetch the segmentation mask coordinates and overlay them on the average image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_xpix, mask_ypix = (\n",
    "    imaging.Segmentation.Mask * imaging.MaskClassification.MaskType\n",
    "    & scan_key\n",
    "    & \"mask_center_z=0\"\n",
    "    & \"mask_npix > 130\"\n",
    "    & \"confidence >= 0.8\"\n",
    ").fetch(\"mask_xpix\", \"mask_ypix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.imshow(average_image,cmap='binary')\n",
    "for i in range(len(mask_xpix)):\n",
    "    plt.scatter(mask_xpix[i], mask_ypix[i], s=1, alpha=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Following this tutorial, we have: \n",
    "+ Covered the essential functionality of `element-calcium-imaging`.\n",
    "+ Learned how to manually insert data into tables.\n",
    "+ Executed and ingested results of image processing with `suite2p`.\n",
    "+ Visualized the results. \n",
    "\n",
    "#### Documentation and DataJoint Tutorials\n",
    "\n",
    "+ [Detailed documentation on\n",
    "  `element-calcium-imaging`.](https://datajoint.com/docs/elements/element-calcium-imaging/)\n",
    "+ [General `datajoint-python`\n",
    "  tutorials.](https://github.com/datajoint/datajoint-tutorials) covering fundamentals,\n",
    "  such as table tiers, query operations, fetch operations, automated computations with the\n",
    "  make function, and more.\n",
    "+ [Documentation for\n",
    "  `datajoint-python`.](https://datajoint.com/docs/core/datajoint-python/)\n",
    "\n",
    "##### Run this tutorial on your own data\n",
    "\n",
    "To run this tutorial notebook on your own data, please use the following steps:\n",
    "+ Download the [mysql-docker image for\n",
    "  DataJoint](https://github.com/datajoint/mysql-docker) and run the container according\n",
    "  to the instructions provide in the repository.\n",
    "+ Create a fork of this repository to your GitHub account.\n",
    "+ Clone the repository and open the files using your IDE.\n",
    "+ Add a code cell immediately after the first code cell in the notebook - we will setup\n",
    "  the local connection using this cell. In this cell, type in the following code. \n",
    "\n",
    "```python\n",
    "import datajoint as dj\n",
    "dj.config[\"database.host\"] = \"localhost\"\n",
    "dj.config[\"database.user\"] = \"<your-username>\"\n",
    "dj.config[\"database.password\"] = \"<your-password>\"\n",
    "dj.config[\"custom\"] = {\"imaging_root_data_dir\": \"path/to/your/data/dir\",\n",
    "\"database_prefix\": \"<your-username_>\"}\n",
    "dj.config.save_local()\n",
    "dj.conn()\n",
    "```\n",
    "\n",
    "+ Run the code block above and proceed with the rest of the notebook."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
