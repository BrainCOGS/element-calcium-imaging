{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('workflow-imaging': conda)",
   "metadata": {
    "interpreter": {
     "hash": "134d995680d44ce2483a761d95a16e9ce77f34191f18929365aa0ab3279667a1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Processing routine\n",
    "\n",
    "+ The following script outlines the steps to ingest acquired metadata (ScanImage and Scanbox) and processed data (Suite2p and CaImAn) into the DataJoint `workflow-calcium-imaging`.\n",
    "\n",
    "+ To ingest with a completely automated workflow, see `03-automate[optional].ipynb`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change into the parent directory to find the `dj_local_conf.json` file. \n",
    "# When you type `import datajoint as dj` the credentials from `dj_local_conf.json` will be used to log into the database.\n",
    "\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from workflow_calcium_imaging.pipeline import *"
   ]
  },
  {
   "source": [
    "## Schema diagrams\n",
    "\n",
    "+ The following outputs are the diagrams of the schemas comprising this workflow.\n",
    "\n",
    "+ Please refer back to these diagrams to visualize the relationships of different tables."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(imaging)"
   ]
  },
  {
   "source": [
    "## Insert an entry into `subject.Subject`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.Subject.insert1(dict(subject='subject1', \n",
    "                             sex='F', \n",
    "                             subject_birth_date='2019-01-01 00:00:01', \n",
    "                             subject_description='no description'))"
   ]
  },
  {
   "source": [
    "## Insert an entry into `lab.Equipment`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Equipment.insert1(dict(scanner='Miniscope-DAQ-V3'))"
   ]
  },
  {
   "source": [
    "## Insert an entry into `session.Session`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.Session.insert1(dict(subject='subject1', \n",
    "                             session_datetime='2021-01-01 00:00:01'))"
   ]
  },
  {
   "source": [
    "## Insert an entry into `session.SessionDirectory`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.SessionDirectory.insert1(dict(subject='subject1', \n",
    "                                      session_datetime='2021-01-01 00:00:01', \n",
    "                                      session_dir='<imaging_root_data_dir>/subject1/session0'))"
   ]
  },
  {
   "source": [
    "## Insert an entry into `scan.Scan`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.Scan.insert1(dict(subject='subject1', \n",
    "                       session_datetime='2021-01-01 00:00:01', \n",
    "                       scan_id=0, \n",
    "                       scanner='Miniscope-DAQ-V3', \n",
    "                       acq_software='Miniscope-DAQ-V3',\n",
    "                       scan_notes=''))"
   ]
  },
  {
   "source": [
    "## Populate `scan.ScanInfo`\n",
    "\n",
    "+ This imported table stores information about the acquired image (e.g. image dimensions, file paths, etc.).\n",
    "+ `populate` automatically calls `make` for every key for which the auto-populated table is missing data.\n",
    "+ `populate_settings` passes arguments to the `populate` method.\n",
    "+ `display_progress=True` reports the progress bar"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_settings = {'display_progress': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.ScanInfo.populate(**populate_settings)"
   ]
  },
  {
   "source": [
    "## Insert an entry into `imaging.ProcessingTask`\n",
    "\n",
    "+ This entry will trigger ingestion of the processed results (i.e. motion correction, segmentation, and traces)\n",
    "\n",
    "+ The `paramset_idx` is the parameter set stored in `imaging.ProcessingParamSet` that is used for the image processing.\n",
    "\n",
    "+ The `processing_output_dir` attribute contains the output directory of the processed results (relative the the imaging root data directory)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.ProcessingTask.insert1(dict(subject='subject1', \n",
    "                                    session_datetime='2021-01-01 00:00:01', \n",
    "                                    scan_id=0,\n",
    "                                    paramset_idx=0,\n",
    "                                    processing_output_dir='<imaging_root_data_dir>/subject1/session0/miniscope_analysis',\n",
    "                                    task_mode='load'))"
   ]
  },
  {
   "source": [
    "## Populate `imaging.Processing`\n",
    "\n",
    "+ For the `task_mode=load` specified above in `imaging.ProcessingTask`, this step ensures that the output directory contains the valid processed outputs.\n",
    "\n",
    "+ In the future, this step will provide for the option to `trigger` the analysis within this workflow (if the `task_mode=trigger`)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Processing.populate(**populate_settings)"
   ]
  },
  {
   "source": [
    "## Populate `imaging.MotionCorrection`\n",
    "\n",
    "+ This table contains the rigid or non-rigid motion correction data including the shifts and summary images.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.MotionCorrection.populate(**populate_settings)"
   ]
  },
  {
   "source": [
    "## Insert an entry into `imaging.Curation`\n",
    "\n",
    "+ The next step in the pipeline is the curation of segmentation results. If a manual curation was implemented, an entry needs to be manually inserted into the table Curation, which specifies the directory to the curated results in curation_output_dir. If we would like to process the processed outcome directly, an entry is also needed in Curation. A method create1_from_processing_task was provided to help this insertion. It copies the processing_output_dir in ProcessingTask to the field curation_output_dir in the table Curation with a new curation_id.\n",
    "\n",
    "+ In this example, we create/insert one `imaging.Curation` for each `imaging.ProcessingTask`, specifying the same output directory."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Curation(dict(subject='subject1', \n",
    "                      session_datetime='2021-01-01 00:00:01', \n",
    "                      scan_id=0,\n",
    "                      paramset_idx=0,\n",
    "                      curation_id=0,\n",
    "                      curation_time='2021-01-01 00:00:01', \n",
    "                      curation_output_dir='<imaging_root_data_dir>/subject1/session0/miniscope_analysis',\n",
    "                      manual_curation=False,\n",
    "                      curation_note=''})"
   ]
  },
  {
   "source": [
    "## Populate `imaging.Segmentation`\n",
    "\n",
    "+ This table contains the mask coordinates, weights, and centers."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Segmentation.populate(**populate_settings)"
   ]
  },
  {
   "source": [
    "## Populate `imaging.MaskClassification`\n",
    "\n",
    "+ This table is currently not implemented."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.MaskClassification.populate(**populate_settings)"
   ]
  },
  {
   "source": [
    "## Populate `imaging.Fluorescence`\n",
    "\n",
    "+ This table contains the fluorescence traces prior filtering and spike extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Fluorescence.populate(**populate_settings)"
   ]
  },
  {
   "source": [
    "## Populate `imaging.Activity`\n",
    "+ This table contains the inferred neural activity from the fluorescence traces."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.Activity.populate(**populate_settings)"
   ]
  },
  {
   "source": [
    "## Proceed to the `04-explore.ipynb` Jupyter Notebook\n",
    "\n",
    "+ This notebook describes the steps to query, fetch, and visualize the imaging data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Insert parameters for Suite2p and CaImAn into the following table:\n",
    "+ imaging.ProcessingParamSet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Define Suite2p parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_suite2p = {'look_one_level_down': 0.0,\n",
    " 'fast_disk': [],\n",
    " 'delete_bin': False,\n",
    " 'mesoscan': False,\n",
    " 'h5py': [],\n",
    " 'h5py_key': 'data',\n",
    " 'save_path0': [],\n",
    " 'subfolders': [],\n",
    " 'nplanes': 1,\n",
    " 'nchannels': 1,\n",
    " 'functional_chan': 1,\n",
    " 'tau': 1.0,\n",
    " 'fs': 10.0,\n",
    " 'force_sktiff': False,\n",
    " 'preclassify': 0.0,\n",
    " 'save_mat': False,\n",
    " 'combined': True,\n",
    " 'aspect': 1.0,\n",
    " 'do_bidiphase': False,\n",
    " 'bidiphase': 0.0,\n",
    " 'do_registration': True,\n",
    " 'keep_movie_raw': False,\n",
    " 'nimg_init': 300,\n",
    " 'batch_size': 500,\n",
    " 'maxregshift': 0.1,\n",
    " 'align_by_chan': 1,\n",
    " 'reg_tif': False,\n",
    " 'reg_tif_chan2': False,\n",
    " 'subpixel': 10,\n",
    " 'smooth_sigma': 1.15,\n",
    " 'th_badframes': 1.0,\n",
    " 'pad_fft': False,\n",
    " 'nonrigid': True,\n",
    " 'block_size': [128, 128],\n",
    " 'snr_thresh': 1.2,\n",
    " 'maxregshiftNR': 5.0,\n",
    " '1Preg': False,\n",
    " 'spatial_hp': 50.0,\n",
    " 'pre_smooth': 2.0,\n",
    " 'spatial_taper': 50.0,\n",
    " 'roidetect': True,\n",
    " 'sparse_mode': False,\n",
    " 'diameter': 12,\n",
    " 'spatial_scale': 0,\n",
    " 'connected': True,\n",
    " 'nbinned': 5000,\n",
    " 'max_iterations': 20,\n",
    " 'threshold_scaling': 1.0,\n",
    " 'max_overlap': 0.75,\n",
    " 'high_pass': 100.0,\n",
    " 'inner_neuropil_radius': 2,\n",
    " 'min_neuropil_pixels': 350,\n",
    " 'allow_overlap': False,\n",
    " 'chan2_thres': 0.65,\n",
    " 'baseline': 'maximin',\n",
    " 'win_baseline': 60.0,\n",
    " 'sig_baseline': 10.0,\n",
    " 'prctile_baseline': 8.0,\n",
    " 'neucoeff': 0.7,\n",
    " 'xrange': np.array([0, 0]),\n",
    " 'yrange': np.array([0, 0])}"
   ]
  },
  {
   "source": [
    "### Insert Suite2p parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.ProcessingParamSet.insert_new_params(\n",
    "    processing_method='suite2p', \n",
    "    package_version='0.9.3',\n",
    "    paramset_idx=0, \n",
    "    paramset_desc='Calcium imaging analysis with Suite2p using default Suite2p parameters', \n",
    "    params=params_suite2p)"
   ]
  },
  {
   "source": [
    "### Define CaImAn 2d planar parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_caiman_2d = {'fnames': None,\n",
    " 'dims': None,\n",
    " 'fr': 30,\n",
    " 'decay_time': 0.4,\n",
    " 'dxy': (1, 1),\n",
    " 'var_name_hdf5': 'mov',\n",
    " 'caiman_version': '1.8.5',\n",
    " 'last_commit': 'GITW-a99c03c9cb221e802ec71aacfb988257810c8c4a',\n",
    " 'mmap_F': None,\n",
    " 'mmap_C': None,\n",
    " 'block_size_spat': 5000,\n",
    " 'dist': 3,\n",
    " 'expandCore': np.array([[0, 0, 1, 0, 0],\n",
    "        [0, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1],\n",
    "        [0, 1, 1, 1, 0],\n",
    "        [0, 0, 1, 0, 0]], dtype='int32'),\n",
    " 'extract_cc': True,\n",
    " 'maxthr': 0.1,\n",
    " 'medw': None,\n",
    " 'method_exp': 'dilate',\n",
    " 'method_ls': 'lasso_lars',\n",
    " 'n_pixels_per_process': None,\n",
    " 'nb': 1,\n",
    " 'normalize_yyt_one': True,\n",
    " 'nrgthr': 0.9999,\n",
    " 'num_blocks_per_run_spat': 20,\n",
    " 'se': np.array([[1, 1, 1],\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 1]], dtype='uint8'),\n",
    " 'ss': np.array([[1, 1, 1],\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 1]], dtype='uint8'),\n",
    " 'thr_method': 'nrg',\n",
    " 'update_background_components': True,\n",
    " 'ITER': 2,\n",
    " 'bas_nonneg': False,\n",
    " 'block_size_temp': 5000,\n",
    " 'fudge_factor': 0.96,\n",
    " 'lags': 5,\n",
    " 'optimize_g': False,\n",
    " 'memory_efficient': False,\n",
    " 'method_deconvolution': 'oasis',\n",
    " 'noise_method': 'mean',\n",
    " 'noise_range': [0.25, 0.5],\n",
    " 'num_blocks_per_run_temp': 20,\n",
    " 'p': 2,\n",
    " 's_min': None,\n",
    " 'solvers': ['ECOS', 'SCS'],\n",
    " 'verbosity': False,\n",
    " 'K': 30,\n",
    " 'SC_kernel': 'heat',\n",
    " 'SC_sigma': 1,\n",
    " 'SC_thr': 0,\n",
    " 'SC_normalize': True,\n",
    " 'SC_use_NN': False,\n",
    " 'SC_nnn': 20,\n",
    " 'alpha_snmf': 100,\n",
    " 'center_psf': False,\n",
    " 'gSig': [5, 5],\n",
    " 'gSiz': (11, 11),\n",
    " 'init_iter': 2,\n",
    " 'kernel': None,\n",
    " 'lambda_gnmf': 1,\n",
    " 'maxIter': 5,\n",
    " 'max_iter_snmf': 500,\n",
    " 'method_init': 'greedy_roi',\n",
    " 'min_corr': 0.85,\n",
    " 'min_pnr': 20,\n",
    " 'nIter': 5,\n",
    " 'normalize_init': True,\n",
    " 'options_local_NMF': None,\n",
    " 'perc_baseline_snmf': 20,\n",
    " 'ring_size_factor': 1.5,\n",
    " 'rolling_length': 100,\n",
    " 'rolling_sum': True,\n",
    " 'seed_method': 'auto',\n",
    " 'sigma_smooth_snmf': (0.5, 0.5, 0.5),\n",
    " 'ssub': 2,\n",
    " 'ssub_B': 2,\n",
    " 'tsub': 2,\n",
    " 'check_nan': True,\n",
    " 'compute_g': False,\n",
    " 'include_noise': False,\n",
    " 'max_num_samples_fft': 3072,\n",
    " 'pixels': None,\n",
    " 'sn': None,\n",
    " 'border_pix': 0,\n",
    " 'del_duplicates': False,\n",
    " 'in_memory': True,\n",
    " 'low_rank_background': True,\n",
    " 'memory_fact': 1,\n",
    " 'n_processes': 1,\n",
    " 'nb_patch': 1,\n",
    " 'only_init': True,\n",
    " 'p_patch': 0,\n",
    " 'remove_very_bad_comps': False,\n",
    " 'rf': None,\n",
    " 'skip_refinement': False,\n",
    " 'p_ssub': 2,\n",
    " 'stride': None,\n",
    " 'p_tsub': 2,\n",
    " 'N_samples_exceptionality': 12,\n",
    " 'batch_update_suff_stat': False,\n",
    " 'dist_shape_update': False,\n",
    " 'ds_factor': 1,\n",
    " 'epochs': 1,\n",
    " 'expected_comps': 500,\n",
    " 'full_XXt': False,\n",
    " 'init_batch': 200,\n",
    " 'init_method': 'bare',\n",
    " 'iters_shape': 5,\n",
    " 'max_comp_update_shape': np.inf,\n",
    " 'max_num_added': 5,\n",
    " 'max_shifts_online': 10,\n",
    " 'min_SNR': 2.5,\n",
    " 'min_num_trial': 5,\n",
    " 'minibatch_shape': 100,\n",
    " 'minibatch_suff_stat': 5,\n",
    " 'motion_correct': True,\n",
    " 'movie_name_online': 'online_movie.mp4',\n",
    " 'normalize': False,\n",
    " 'n_refit': 0,\n",
    " 'num_times_comp_updated': np.inf,\n",
    " 'opencv_codec': 'H264',\n",
    " 'path_to_model': None,\n",
    " 'ring_CNN': False,\n",
    " 'rval_thr': 0.8,\n",
    " 'save_online_movie': False,\n",
    " 'show_movie': False,\n",
    " 'simultaneously': False,\n",
    " 'sniper_mode': False,\n",
    " 'stop_detection': False,\n",
    " 'test_both': False,\n",
    " 'thresh_CNN_noisy': 0.5,\n",
    " 'thresh_fitness_delta': -50,\n",
    " 'thresh_fitness_raw': -60.97977932734429,\n",
    " 'thresh_overlap': 0.5,\n",
    " 'update_freq': 200,\n",
    " 'update_num_comps': True,\n",
    " 'use_corr_img': False,\n",
    " 'use_dense': True,\n",
    " 'use_peak_max': True,\n",
    " 'W_update_factor': 1,\n",
    " 'SNR_lowest': 0.5,\n",
    " 'cnn_lowest': 0.1,\n",
    " 'gSig_range': None,\n",
    " 'min_cnn_thr': 0.9,\n",
    " 'rval_lowest': -1,\n",
    " 'use_cnn': True,\n",
    " 'use_ecc': False,\n",
    " 'max_ecc': 3,\n",
    " 'do_merge': True,\n",
    " 'merge_thr': 0.8,\n",
    " 'merge_parallel': False,\n",
    " 'max_merge_area': None,\n",
    " 'border_nan': 'copy',\n",
    " 'gSig_filt': None,\n",
    " 'is3D': False,\n",
    " 'max_deviation_rigid': 3,\n",
    " 'max_shifts': (6, 6),\n",
    " 'min_mov': None,\n",
    " 'niter_rig': 1,\n",
    " 'nonneg_movie': True,\n",
    " 'num_frames_split': 80,\n",
    " 'num_splits_to_process_els': None,\n",
    " 'num_splits_to_process_rig': None,\n",
    " 'overlaps': (32, 32),\n",
    " 'pw_rigid': False,\n",
    " 'shifts_opencv': True,\n",
    " 'splits_els': 14,\n",
    " 'splits_rig': 14,\n",
    " 'strides': (96, 96),\n",
    " 'upsample_factor_grid': 4,\n",
    " 'use_cuda': False,\n",
    " 'n_channels': 2,\n",
    " 'use_bias': False,\n",
    " 'use_add': False,\n",
    " 'pct': 0.01,\n",
    " 'patience': 3,\n",
    " 'max_epochs': 100,\n",
    " 'width': 5,\n",
    " 'loss_fn': 'pct',\n",
    " 'lr': 0.001,\n",
    " 'lr_scheduler': None,\n",
    " 'remove_activity': False,\n",
    " 'reuse_model': False}"
   ]
  },
  {
   "source": [
    "### Insert CaImAn parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.ProcessingParamSet.insert_new_params(\n",
    "    processing_method='caiman', \n",
    "    package_version='1.8.7', \n",
    "    paramset_idx=1, \n",
    "    paramset_desc='Calcium imaging analysis with CaImAn using default CaImAn parameters for 2d planar images', \n",
    "    params=params_caiman_2d)"
   ]
  },
  {
   "source": [
    "### Define CaImAn 3d volumetric parameters\n",
    "    strides    = (96, 96, 1)\n",
    "    overlaps   = (32, 32, 1)\n",
    "    max_shifts = (6, 6, 1)\n",
    "    gSig       = (5, 5, 1)\n",
    "    use_cnn    = False"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_caiman_3d = {'fnames': None,\n",
    " 'dims': None,\n",
    " 'fr': 30,\n",
    " 'decay_time': 0.4,\n",
    " 'dxy': (1, 1),\n",
    " 'var_name_hdf5': 'mov',\n",
    " 'caiman_version': '1.8.5',\n",
    " 'last_commit': 'GITW-a99c03c9cb221e802ec71aacfb988257810c8c4a',\n",
    " 'mmap_F': None,\n",
    " 'mmap_C': None,\n",
    " 'block_size_spat': 5000,\n",
    " 'dist': 3,\n",
    " 'expandCore': np.array([[0, 0, 1, 0, 0],\n",
    "        [0, 1, 1, 1, 0],\n",
    "        [1, 1, 1, 1, 1],\n",
    "        [0, 1, 1, 1, 0],\n",
    "        [0, 0, 1, 0, 0]], dtype='int32'),\n",
    " 'extract_cc': True,\n",
    " 'maxthr': 0.1,\n",
    " 'medw': None,\n",
    " 'method_exp': 'dilate',\n",
    " 'method_ls': 'lasso_lars',\n",
    " 'n_pixels_per_process': None,\n",
    " 'nb': 1,\n",
    " 'normalize_yyt_one': True,\n",
    " 'nrgthr': 0.9999,\n",
    " 'num_blocks_per_run_spat': 20,\n",
    " 'se': np.array([[1, 1, 1],\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 1]], dtype='uint8'),\n",
    " 'ss': np.array([[1, 1, 1],\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 1]], dtype='uint8'),\n",
    " 'thr_method': 'nrg',\n",
    " 'update_background_components': True,\n",
    " 'ITER': 2,\n",
    " 'bas_nonneg': False,\n",
    " 'block_size_temp': 5000,\n",
    " 'fudge_factor': 0.96,\n",
    " 'lags': 5,\n",
    " 'optimize_g': False,\n",
    " 'memory_efficient': False,\n",
    " 'method_deconvolution': 'oasis',\n",
    " 'noise_method': 'mean',\n",
    " 'noise_range': [0.25, 0.5],\n",
    " 'num_blocks_per_run_temp': 20,\n",
    " 'p': 2,\n",
    " 's_min': None,\n",
    " 'solvers': ['ECOS', 'SCS'],\n",
    " 'verbosity': False,\n",
    " 'K': 30,\n",
    " 'SC_kernel': 'heat',\n",
    " 'SC_sigma': 1,\n",
    " 'SC_thr': 0,\n",
    " 'SC_normalize': True,\n",
    " 'SC_use_NN': False,\n",
    " 'SC_nnn': 20,\n",
    " 'alpha_snmf': 100,\n",
    " 'center_psf': False,\n",
    " 'gSig': (5, 5, 1),\n",
    " 'gSiz': (11, 11),\n",
    " 'init_iter': 2,\n",
    " 'kernel': None,\n",
    " 'lambda_gnmf': 1,\n",
    " 'maxIter': 5,\n",
    " 'max_iter_snmf': 500,\n",
    " 'method_init': 'greedy_roi',\n",
    " 'min_corr': 0.85,\n",
    " 'min_pnr': 20,\n",
    " 'nIter': 5,\n",
    " 'normalize_init': True,\n",
    " 'options_local_NMF': None,\n",
    " 'perc_baseline_snmf': 20,\n",
    " 'ring_size_factor': 1.5,\n",
    " 'rolling_length': 100,\n",
    " 'rolling_sum': True,\n",
    " 'seed_method': 'auto',\n",
    " 'sigma_smooth_snmf': (0.5, 0.5, 0.5),\n",
    " 'ssub': 2,\n",
    " 'ssub_B': 2,\n",
    " 'tsub': 2,\n",
    " 'check_nan': True,\n",
    " 'compute_g': False,\n",
    " 'include_noise': False,\n",
    " 'max_num_samples_fft': 3072,\n",
    " 'pixels': None,\n",
    " 'sn': None,\n",
    " 'border_pix': 0,\n",
    " 'del_duplicates': False,\n",
    " 'in_memory': True,\n",
    " 'low_rank_background': True,\n",
    " 'memory_fact': 1,\n",
    " 'n_processes': 1,\n",
    " 'nb_patch': 1,\n",
    " 'only_init': True,\n",
    " 'p_patch': 0,\n",
    " 'remove_very_bad_comps': False,\n",
    " 'rf': None,\n",
    " 'skip_refinement': False,\n",
    " 'p_ssub': 2,\n",
    " 'stride': None,\n",
    " 'p_tsub': 2,\n",
    " 'N_samples_exceptionality': 12,\n",
    " 'batch_update_suff_stat': False,\n",
    " 'dist_shape_update': False,\n",
    " 'ds_factor': 1,\n",
    " 'epochs': 1,\n",
    " 'expected_comps': 500,\n",
    " 'full_XXt': False,\n",
    " 'init_batch': 200,\n",
    " 'init_method': 'bare',\n",
    " 'iters_shape': 5,\n",
    " 'max_comp_update_shape': np.inf,\n",
    " 'max_num_added': 5,\n",
    " 'max_shifts_online': 10,\n",
    " 'min_SNR': 2.5,\n",
    " 'min_num_trial': 5,\n",
    " 'minibatch_shape': 100,\n",
    " 'minibatch_suff_stat': 5,\n",
    " 'motion_correct': True,\n",
    " 'movie_name_online': 'online_movie.mp4',\n",
    " 'normalize': False,\n",
    " 'n_refit': 0,\n",
    " 'num_times_comp_updated': np.inf,\n",
    " 'opencv_codec': 'H264',\n",
    " 'path_to_model': None,\n",
    " 'ring_CNN': False,\n",
    " 'rval_thr': 0.8,\n",
    " 'save_online_movie': False,\n",
    " 'show_movie': False,\n",
    " 'simultaneously': False,\n",
    " 'sniper_mode': False,\n",
    " 'stop_detection': False,\n",
    " 'test_both': False,\n",
    " 'thresh_CNN_noisy': 0.5,\n",
    " 'thresh_fitness_delta': -50,\n",
    " 'thresh_fitness_raw': -60.97977932734429,\n",
    " 'thresh_overlap': 0.5,\n",
    " 'update_freq': 200,\n",
    " 'update_num_comps': True,\n",
    " 'use_corr_img': False,\n",
    " 'use_dense': True,\n",
    " 'use_peak_max': True,\n",
    " 'W_update_factor': 1,\n",
    " 'SNR_lowest': 0.5,\n",
    " 'cnn_lowest': 0.1,\n",
    " 'gSig_range': None,\n",
    " 'min_cnn_thr': 0.9,\n",
    " 'rval_lowest': -1,\n",
    " 'use_cnn': False,\n",
    " 'use_ecc': False,\n",
    " 'max_ecc': 3,\n",
    " 'do_merge': True,\n",
    " 'merge_thr': 0.8,\n",
    " 'merge_parallel': False,\n",
    " 'max_merge_area': None,\n",
    " 'border_nan': 'copy',\n",
    " 'gSig_filt': None,\n",
    " 'is3D': False,\n",
    " 'max_deviation_rigid': 3,\n",
    " 'max_shifts': (6, 6, 1),\n",
    " 'min_mov': None,\n",
    " 'niter_rig': 1,\n",
    " 'nonneg_movie': True,\n",
    " 'num_frames_split': 80,\n",
    " 'num_splits_to_process_els': None,\n",
    " 'num_splits_to_process_rig': None,\n",
    " 'overlaps': (32, 32, 1),\n",
    " 'pw_rigid': False,\n",
    " 'shifts_opencv': True,\n",
    " 'splits_els': 14,\n",
    " 'splits_rig': 14,\n",
    " 'strides': (96, 96, 1),\n",
    " 'upsample_factor_grid': 4,\n",
    " 'use_cuda': False,\n",
    " 'n_channels': 2,\n",
    " 'use_bias': False,\n",
    " 'use_add': False,\n",
    " 'pct': 0.01,\n",
    " 'patience': 3,\n",
    " 'max_epochs': 100,\n",
    " 'width': 5,\n",
    " 'loss_fn': 'pct',\n",
    " 'lr': 0.001,\n",
    " 'lr_scheduler': None,\n",
    " 'remove_activity': False,\n",
    " 'reuse_model': False}"
   ]
  },
  {
   "source": [
    "### Insert CaImAn parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.ProcessingParamSet.insert_new_params(\n",
    "    processing_method='caiman', \n",
    "    package_version='1.8.7', \n",
    "    paramset_idx=2, \n",
    "    paramset_desc='Calcium imaging analysis with CaImAn using default CaImAn parameters for 3d volumetric images', \n",
    "    params=params_caiman_3d)"
   ]
  },
  {
   "source": [
    "## Insert entries into the following manual DataJoint tables\n",
    "\n",
    "+ subject.Subject\n",
    "+ experiment.Equipment\n",
    "+ experiment.Session\n",
    "+ scan.Scan\n",
    "+ imaging.ProcessingTask\n",
    "\n",
    "As described in the following sections, the entries can be inserted manually, or with the `ingest` method and accompanying `csv` files."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.Subject.insert1(dict(subject='subject1', \n",
    "                             sex='F', \n",
    "                             subject_birth_date='2019-01-01 00:00:01', \n",
    "                             subject_description='no description'))\n",
    "\n",
    "Equipment.insert1(dict(scanner='MINI2P_ImagingScanner'))\n",
    "\n",
    "Session.insert1(dict(subject='subject1', \n",
    "                     session_datetime='2021-01-01 00:00:01'))\n",
    "\n",
    "Session.Directory.insert1(dict(subject='subject1', \n",
    "                               session_datetime='2021-01-01 00:00:01', \n",
    "                               session_dir='<imaging_root_data_dir>/subject1/session0'))\n",
    "\n",
    "scan.Scan.insert1(dict(subject='subject1', \n",
    "                       session_datetime='2021-01-01 00:00:01', \n",
    "                       scan_id=0, \n",
    "                       scanner='MINI2P_ImagingScanner', \n",
    "                       scan_notes=''))\n",
    "\n",
    "imaging.ProcessingTask.insert1(dict(subject='subject1', \n",
    "                                    session_datetime='2021-01-01 00:00:01', \n",
    "                                    scan_id=0, \n",
    "                                    paramset_idx=0, \n",
    "                                    task_mode='load'))"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Populate the following imported and computed DataJoint tables\n",
    "\n",
    "+ scan.ScanInfo\n",
    "+ imaging.Processing\n",
    "+ imaging.MotionCorrection\n",
    "+ imaging.Segmentation\n",
    "+ imaging.MaskClassification\n",
    "+ imaging.Fluorescence\n",
    "+ imaging.Activity\n",
    "\n",
    "As described in the following sections, populating the tables can be done individually or with the `populate` method."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_settings = {'display_progress': True, 'reserve_jobs': False, 'suppress_errors': False}\n",
    "\n",
    "scan.ScanInfo.populate(**populate_settings)\n",
    "imaging.Processing.populate(**populate_settings)\n",
    "imaging.MotionCorrection.populate(**populate_settings)\n",
    "imaging.Segmentation.populate(**populate_settings)\n",
    "imaging.MaskClassification.populate(**populate_settings)\n",
    "imaging.Fluorescence.populate(**populate_settings)\n",
    "imaging.Activity.populate(**populate_settings)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Insert new ProcessingTask to trigger ingestion of motion-correction/segmentation results\n",
    "\n",
    "Motion correction and segmentation are performed for each scan,\n",
    "once the processing job has been completed, an entry in the `ProcessingTask` needs to be added to trigger the ingestion of the processing results.\n",
    "\n",
    "Two pieces of information need to be specified:\n",
    "+ the `paramset_idx` used for the processing job\n",
    "+ the output directory storing the processing results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan.Scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from workflow_imaging.paths import get_imaging_root_data_dir\n",
    "\n",
    "root_dir = pathlib.Path(get_imaging_root_data_dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scan_key in (scan.Scan & scan.ScanInfo - imaging.ProcessingTask).fetch('KEY'):\n",
    "    scan_file = root_dir / (scan.ScanInfo.ScanFile & scan_key).fetch('file_path')[0]\n",
    "    recording_dir = scan_file.parent\n",
    "    # suite2p\n",
    "    suite2p_dir = recording_dir / 'suite2p'\n",
    "    if suite2p_dir.exists():\n",
    "        imaging.ProcessingTask.insert1({**scan_key,\n",
    "                                        'paramset_idx': 0,\n",
    "                                        'processing_output_dir': suite2p_dir.as_posix()})\n",
    "    # caiman\n",
    "    caiman_dir = recording_dir / 'caiman'\n",
    "    if caiman_dir.exists():\n",
    "        is_3D = (scan.ScanInfo & scan_key).fetch1('ndepths') > 1\n",
    "        imaging.ProcessingTask.insert1({**scan_key,\n",
    "                                        'paramset_idx': 1 if not is_3D else 2,\n",
    "                                        'processing_output_dir': caiman_dir.as_posix()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.ProcessingTask()"
   ]
  },
  {
   "source": [
    "## Insert new Curation following the ProcessingTask\n",
    "\n",
    "In this example, we create/insert one Curation for each ClusteringTask, specifying the same output directory\n",
    "\n",
    "To this end, we make use of a convenient function `imaging.Curation().create1_from_processing_task()`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in (imaging.ProcessingTask - imaging.Curation).fetch('KEY'):\n",
    "    imaging.Curation().create1_from_processing_task(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}