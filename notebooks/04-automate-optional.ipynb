{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run workflow in an automatic way\n",
    "\n",
    "In the previous notebook [03-process](03-process.ipynb), we ran through the workflow in detailed steps. For daily running routines, the current notebook provides a more succinct and automatic approach to run through the pipeline using some utility functions in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "import numpy as np\n",
    "from workflow_calcium_imaging.pipeline import lab, subject, session, scan, imaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion of subjects, sessions, scans\n",
    "\n",
    "1. Fill subject and session information in files `/user_data/subjects.csv` and `/user_data/sessions.csv`\n",
    "2. Run automatic scripts prepared in `workflow_calcium_imaging.ingest` for ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow_calcium_imaging.ingest import ingest_subjects, ingest_sessions\n",
    "\n",
    "ingest_subjects()\n",
    "ingest_sessions() # ingest Equipment, session.Session, session.SessionDirectory, scan.Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Insert new ProcessingParamSet for Suite2p or CaImAn\n",
    "\n",
    "This is not needed if you are using an existing ProcessingParamSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params_suite2p = {'look_one_level_down': 0.0,\n",
    "                  'fast_disk': [],\n",
    "                  'delete_bin': False,\n",
    "                  'mesoscan': False,\n",
    "                  'h5py': [],\n",
    "                  'h5py_key': 'data',\n",
    "                  'save_path0': [],\n",
    "                  'subfolders': [],\n",
    "                  'nplanes': 1,\n",
    "                  'nchannels': 1,\n",
    "                  'functional_chan': 1,\n",
    "                  'tau': 1.0,\n",
    "                  'fs': 10.0,\n",
    "                  'force_sktiff': False,\n",
    "                  'preclassify': 0.0,\n",
    "                  'save_mat': False,\n",
    "                  'combined': True,\n",
    "                  'aspect': 1.0,\n",
    "                  'do_bidiphase': False,\n",
    "                  'bidiphase': 0.0,\n",
    "                  'do_registration': True,\n",
    "                  'keep_movie_raw': False,\n",
    "                  'nimg_init': 300,\n",
    "                  'batch_size': 500,\n",
    "                  'maxregshift': 0.1,\n",
    "                  'align_by_chan': 1,\n",
    "                  'reg_tif': False,\n",
    "                  'reg_tif_chan2': False,\n",
    "                  'subpixel': 10,\n",
    "                  'smooth_sigma': 1.15,\n",
    "                  'th_badframes': 1.0,\n",
    "                  'pad_fft': False,\n",
    "                  'nonrigid': True,\n",
    "                  'block_size': [128, 128],\n",
    "                  'snr_thresh': 1.2,\n",
    "                  'maxregshiftNR': 5.0,\n",
    "                  '1Preg': False,\n",
    "                  'spatial_hp': 50.0,\n",
    "                  'pre_smooth': 2.0,\n",
    "                  'spatial_taper': 50.0,\n",
    "                  'roidetect': True,\n",
    "                  'sparse_mode': False,\n",
    "                  'diameter': 12,\n",
    "                  'spatial_scale': 0,\n",
    "                  'connected': True,\n",
    "                  'nbinned': 5000,\n",
    "                  'max_iterations': 20,\n",
    "                  'threshold_scaling': 1.0,\n",
    "                  'max_overlap': 0.75,\n",
    "                  'high_pass': 100.0,\n",
    "                  'inner_neuropil_radius': 2,\n",
    "                  'min_neuropil_pixels': 350,\n",
    "                  'allow_overlap': False,\n",
    "                  'chan2_thres': 0.65,\n",
    "                  'baseline': 'maximin',\n",
    "                  'win_baseline': 60.0,\n",
    "                  'sig_baseline': 10.0,\n",
    "                  'prctile_baseline': 8.0,\n",
    "                  'neucoeff': 0.7,\n",
    "                  'xrange': np.array([0, 0]),\n",
    "                  'yrange': np.array([0, 0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.ProcessingParamSet.insert_new_params(\n",
    "    processing_method='suite2p', \n",
    "    package_version='0.9.3',\n",
    "    paramset_idx=0, \n",
    "    params=params_suite2p,\n",
    "    paramset_desc='Calcium imaging analysis with Suite2p using default Suite2p parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigger autoprocessing of the remaining calcium imaging workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow_calcium_imaging import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `process.run()` function in the workflow populates every auto-processing table in the workflow. If a table is dependent on a manual table upstream, it will not get populated until the manual table is inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this stage, process script populates through the table upstream of `ProcessingTask`\n",
    "process.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert new ProcessingTask to trigger ingestion of processing results\n",
    "\n",
    "To populate the rest of the tables in the workflow, an entry in the `ProcessingTask` needs to be added to trigger the ingestion of the processing results, with the two pieces of information specified:\n",
    "+ `paramset_idx` used for the processing job\n",
    "+ output directory storing the processing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_key = session.Session.fetch1('KEY')\n",
    "\n",
    "imaging.ProcessingTask.insert1(dict(session_key, \n",
    "                                    scan_id=0,\n",
    "                                    paramset_idx=0,\n",
    "                                    processing_output_dir='/subject3/session1/suite2p',\n",
    "                                    task_mode='load'), skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run populate again for table `imaging.Processing`\n",
    "process.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert new Curation to trigger ingestion of curated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = (imaging.ProcessingTask & session_key).fetch1('KEY')\n",
    "imaging.Curation().create1_from_processing_task(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run populate for the rest of the tables in the workflow (takes a while)\n",
    "process.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and next step\n",
    "\n",
    "This notebook runs through the workflow in an automatic manner, in the next notebook [05-explore](05-explore.ipynb), we will introduce how to query, fetch and visualize the contents we ingested into the tables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ephys_workflow_runner",
   "language": "python",
   "name": "ephys_workflow_runner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}